// import { streamText } from "ai";
// import { createOpenAI } from "@ai-sdk/openai";
// import { initialMessage } from "@/lib/data";

// const openai = createOpenAI({
//   // apiKey: envConfig.NEXT_PUBLIC_OPENAI_API_KEY || "",
//   apiKey: process.env.OPENAI_API_KEY || "",
//   compatibility: "strict",
// });

// export const runtime = "edge";
// export async function POST(req: Request) {
//   try {
//     const { messages } = await req.json();
//     const stream = await streamText({
//       model: openai("gpt-3.5-turbo"),
//       messages: [initialMessage, ...messages],
//       temperature: 1,
//     });
//     // console.log(messages)
//     return stream?.toDataStreamResponse();
//   } catch (error) {
//     console.error("Error:", error); // In chi ti·∫øt l·ªói ra console
//     return new Response("An error occurred.", { status: 500 });
//   }
// }

import { streamText } from "ai";
import { createOpenAI } from "@ai-sdk/openai";
import { openaiEmbed } from "@/lib/openai";
import { pineconeIndex } from "@/lib/pinecone";

const openai = createOpenAI({
  apiKey: process.env.OPENAI_API_KEY || "",
  compatibility: "strict",
});

// Ch·∫°y tr√™n Node.js ƒë·ªÉ tr√°nh l·ªói "crypto"
export const runtime = "nodejs";

export async function POST(req: Request) {
  try {
    const { messages } = await req.json();

    const userQuery = messages[messages.length - 1].content; // L·∫•y c√¢u h·ªèi cu·ªëi c√πng c·ªßa user

    // Chuy·ªÉn c√¢u h·ªèi c·ªßa user th√†nh embeddings
    const queryEmbeddingRes = await openaiEmbed.embeddings.create({
      model: "text-embedding-ada-002",
      input: userQuery,
    });
    const queryVector = queryEmbeddingRes.data[0].embedding; // L·∫•y vector c·ªßa c√¢u h·ªèi

    // T√¨m ki·∫øm s·∫£n ph·∫©m ph√π h·ª£p trong Pinecone
    const searchResults = await pineconeIndex.query({
      vector: queryVector, // So s√°nh vector c·ªßa c√¢u h·ªèi v·ªõi database
      topK: 5, // L·∫•y 5 k·∫øt qu·∫£ ph√π h·ª£p (g·ªìm s·∫£n ph·∫©m v√† n·ªôi dung web)
      includeMetadata: true, // L·∫•y lu√¥n metadata
    });

    // T√°ch s·∫£n ph·∫©m v√† n·ªôi dung website
    const productMatches = searchResults.matches.filter(
      (match) => match.metadata?.type !== "website"
    );
    const websiteMatch = searchResults.matches.find(
      (match) => match.metadata?.type === "website"
    );

    let websiteInfo = "";
    if (websiteMatch) {
      websiteInfo = `\n\nTh√¥ng tin h·ªØu √≠ch t·ª´ website:\n${websiteMatch.metadata?.content}`;
    }
    // console.log(websiteInfo);
    // Format danh s√°ch s·∫£n ph·∫©m
    const productList = productMatches
      .map(
        (match) =>
          `T√™n: ${match.metadata?.name} | Gi√°: ${match.metadata?.price} VND | üîó [Xem s·∫£n ph·∫©m](${match.metadata?.link})`//kh√¥ng c·∫ßn m√¥ t·∫£ v√¨ ƒë√£ ki·∫øm ƒë∆∞·ª£c s·∫£n ph·∫©m ph√π h·ª£p r·ªìi kh√¥ng c·∫ßn t·ªën th√™m ti·ªÅn cho chat
      )
      .join("\n");

    // console.log(productList);
    // C·∫≠p nh·∫≠t context chatbot v·ªõi danh s√°ch s·∫£n ph·∫©m
    
    const updatedMessages = [
      {
        role: "system",
        content: `${websiteInfo} - Nh·ªØng s·∫£n ph·∫©m ph√π h·ª£p:\n\n${productList}.`,
      },
      ...messages,
    ];
    console.log(updatedMessages)
    const stream = await streamText({
      model: openai("gpt-3.5-turbo"),
      messages: updatedMessages,
      temperature: 1,
    });

    return stream?.toDataStreamResponse();
  } catch (error) {
    console.error("L·ªói chatbot:", error);
    return new Response("L·ªói server", { status: 500 });
  }
}
